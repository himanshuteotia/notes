# ğŸ§  **Caching Patterns in Distributed Systems**

**Caching** is a technique used to **store data temporarily** to reduce the **load on databases**, improve **performance**, and **decrease latency**. In distributed systems, caching plays a critical role in scaling applications and ensuring high availability.

---

## âš¡ **Why Use Caching?**
- ğŸš€ **Improves Performance:** Faster data retrieval.
- ğŸ’° **Reduces Costs:** Minimizes database calls.
- ğŸ§® **Increases Scalability:** Handles more user requests.
- âš¡ **Reduces Latency:** Especially for read-heavy applications.

---

## ğŸ“Š **Types of Caches:**
1. **In-Memory Cache** (e.g., Redis, Memcached) â†’ Fastest but volatile.
2. **Distributed Cache** (e.g., Redis Cluster, Hazelcast) â†’ Shared across multiple instances.
3. **Local Cache** (e.g., LRU Cache in Node.js) â†’ Resides within the application.

---

## ğŸ¯ **Common Caching Patterns:**

### âœ… **1. Cache-Aside (Lazy Loading)**
**Most common caching strategy.**

- The application checks the cache before hitting the database.
- If the data is not in the cache (**cache miss**), fetch from DB and update the cache.

**ğŸ“Š Workflow:**
```
Client â†’ Cache (miss) â†’ Database â†’ Cache (store) â†’ Client
```

**ğŸ’¡ Use Case:** Ideal for read-heavy applications with occasional writes.

**Example (Node.js + Redis):**
```javascript
const redis = require('redis');
const client = redis.createClient();
const { promisify } = require('util');
const getAsync = promisify(client.get).bind(client);
const setAsync = promisify(client.set).bind(client);

async function getUser(userId) {
  const cachedData = await getAsync(userId);

  if (cachedData) {
    return JSON.parse(cachedData); // Cache hit
  }

  // Cache miss, fetch from DB
  const userData = await db.query(`SELECT * FROM users WHERE id = ${userId}`);
  await setAsync(userId, JSON.stringify(userData), 'EX', 60); // Expires in 60s
  return userData;
}
```

---

### âœ… **2. Read-Through Cache**
The application interacts directly with the cache. If the cache misses, it loads data from the database **and** updates the cache automatically.

**ğŸ“Š Workflow:**
```
Client â†’ Cache â†’ (miss) â†’ Database â†’ Cache â†’ Client
```

**ğŸ’¡ Use Case:** Simplifies application code but can introduce latency during cache misses.

---

### âœ… **3. Write-Through Cache**
Every write operation goes through the cache **first**. The cache writes the data to the database **immediately**.

**ğŸ“Š Workflow:**
```
Client â†’ Cache â†’ Database
```

**ğŸ’¡ Use Case:** Ensures cache consistency with DB but increases write latency.

---

### âœ… **4. Write-Behind (Write-Back) Cache**
Similar to **Write-Through**, but the cache writes data to the database **asynchronously** after a short delay.

**ğŸ“Š Workflow:**
```
Client â†’ Cache (ack) â†’ Database (delayed write)
```

**ğŸ’¡ Use Case:** Optimizes write performance but risks data loss if cache fails before writing to the DB.

---

### âœ… **5. Cache Invalidation Patterns**
Managing data freshness is critical in caching. These patterns ensure the cache doesnâ€™t serve stale data.

#### ğŸ”¸ **Time-To-Live (TTL):**
- Set an expiry time for cached data.

```javascript
await setAsync('key', JSON.stringify(data), 'EX', 60); // 60 sec TTL
```

#### ğŸ”¸ **Explicit Invalidation:**
- Invalidate cache entries when data is updated.

```javascript
await client.del('key'); // Remove from cache after DB update
```

#### ğŸ”¸ **Write-Through with Invalidation:**
- Invalidate cache on **writes** and **re-populate** on next read.

---

### âœ… **6. Cache Busting (Versioning)**
When a large set of cached data needs to be invalidated, **cache versioning** is used.

**Example:**
```javascript
const version = 'v2';
const cacheKey = `${version}:user:${userId}`;
```
- Changing `v2` to `v3` invalidates all old cache entries.

---

### âœ… **7. Content Delivery Network (CDN) Caching**
For static assets (images, CSS, JS), CDNs cache data at edge servers close to users.

**ğŸ’¡ Use Case:** Optimizes performance for static content delivery.

---

### âœ… **8. Two-Tier Caching**
Combines **local cache** and **distributed cache**.

1. App checks local cache (fastest).
2. If a **miss**, it checks the distributed cache.
3. If another **miss**, it fetches from the DB and updates both caches.

**ğŸ’¡ Use Case:** Reduces network calls and improves response time.

---

### âœ… **9. Cache Stampede Prevention**
Occurs when many clients request the same data at once, causing a surge of DB hits on cache expiration.

**Prevention Techniques:**
- **Locking:** Only one process can fetch and update the cache.
- **Stale-While-Revalidate:** Serve stale data while fetching fresh data in the background.
- **Randomized TTL:** Add randomness to expiry times to avoid simultaneous cache misses.

---

### âœ… **10. Sharded Caching**
Divide the cache across multiple nodes to scale horizontally.

**ğŸ’¡ Use Case:** Used in large-scale systems like **Twitter** or **Facebook** to handle massive traffic.

---

## âš–ï¸ **Comparison of Caching Patterns:**

| **Pattern**          | **Read Performance** | **Write Performance** | **Consistency** | **Use Case**              |
|----------------------|----------------------|-----------------------|-----------------|---------------------------|
| **Cache-Aside**       | â­â­â­â­                 | â­â­                    | Weak            | Read-heavy systems        |
| **Read-Through**      | â­â­â­â­                 | â­â­                    | Strong          | Simple caching logic      |
| **Write-Through**     | â­â­â­                  | â­â­                    | Strong          | Strong consistency needs  |
| **Write-Behind**      | â­â­â­â­                 | â­â­â­â­                  | Eventual        | High write performance    |
| **Two-Tier Caching**   | â­â­â­â­â­                | â­â­                    | Strong/Weak     | Low-latency requirements  |
| **Sharded Caching**    | â­â­â­â­â­                | â­â­â­â­                  | Strong/Weak     | High scalability systems  |

---

## ğŸ’¥ **Best Practices:**

1. âœ… **Use TTLs** to avoid stale data.
2. âœ… **Monitor cache hit/miss ratios**.
3. âœ… **Design for cache failures** â€” always have a fallback to the database.
4. âœ… **Evict rarely-used data** using strategies like **LRU (Least Recently Used)** or **LFU (Least Frequently Used)**.
5. âœ… **Ensure idempotency** in write-behind strategies.

---

## ğŸ’¡ **When to Avoid Caching:**
- ğŸ”¥ In real-time systems that require strong consistency.
- ğŸ”¥ If the data is highly dynamic and changes frequently.
- ğŸ”¥ For security-sensitive data (unless encrypted).

---

## ğŸ† **Final Thoughts:**
- Choose the right caching pattern based on **read/write ratios**, **consistency needs**, and **failure tolerance**.
- A well-designed caching strategy can **improve performance by 10x** while reducing infrastructure costs.